### 流式分析

#### 1、Event Time 和 Watermarks

##### 1.1、概要

Flink 明确支持以下三种时间语义：

- *事件时间（event time）*：事件产生的时间，记录的是设备生成（或存储）事件的时间
- *摄取时间（ingestion time）*：Flink 读取事件的时间
- *处理时间（processing time）*：Flink pipeline 中具体处理事件的时间

为了获取可重现的结果，比如，计算过去某一天第一个小时股票的最高价格时，应该使用事件时间。如果使用处理时间的话，实时应用程序的结果是由程序运行的时间所决定。多次运行基于处理时间的实时程序，可能得到的结果都不相同，也可能会导致再次分析历史数据或者测试新代码变得异常困难。

##### 1.2、使用 Event Time

如果要使用事件时间，需要额外给 Flink 提供一个时间戳提取器和 Watermark 生成器，Flink 将使用它们来跟踪事件时间的进度。

##### 1.3、Watermarks

比如，如下带有混乱时间戳的事件流。显示的数字表达的是这些事件实际发生时间的时间戳。到达的第一个事件发生在时间 4，随后发生的事件发生在更早的时间 2，依此类推：

###### ··· 23 19 22 24 21 14 17 13 12 15 9 11 7 2 4 

如果要对数据流排序：应用程序应该在数据流里的事件到达时就有一个算子（暂且称之为排序）开始处理事件，这个算子所输出的流是按照时间戳排序好的。

重新审视一下这些数据:

1. 排序器看到的第一个事件的时间戳是 4，但是不能立即将其作为已排序的流释放。因为并不能确定它是有序的，并且较早的事件有可能并未到达。因此，*需要一些缓冲，要等一些时间*。

2. 如果一直等待，那么永远不会有结果。

3. 需要一种策略：对于任何给定时间戳的事件，Flink 何时停止等待较早事件的到来。*watermarks 的作用就是定义何时停止等待较早的事件*。

   Flink 中事件时间的处理取决于 *watermark 生成器*，后者将带有时间戳的特殊元素插入流中形成 *watermarks*。事件时间 *t* 的 watermark 代表 *t* 之前（很可能）都已经到达。

4. 如何决定 watermarks 的不同生成策略

   每个事件都会延迟一段时间后到达，然而这些延迟有所不同，有些事件可能比其他事件延迟得更多。一种简单的方法是假定这些延迟受某个最大延迟的限制。Flink 将此策略称为 *最大无序边界 (bounded-out-of-orderness)* watermark。

##### 1.4、延迟 VS 正确性

watermarks 使开发人员在开发应用程序时可以控制延迟和完整性之间的权衡。与批处理不同，批处理中可以在产生任何结果之前完全了解输入，而使用流式传输，不能等待所有的时间都产生了，才输出排序好的数据。

可以把 watermarks 的边界时间配置的相对较短，从而冒着在输入了解不完全的情况下产生结果的风险-即可能会很快产生错误结果。或者，以等待更长的时间，并利用对输入流的更全面的了解来产生结果。

当然也可以实施混合解决方案，先快速产生初步结果，然后在处理其他（最新）数据时向这些结果提供更新。对于有一些对延迟的容忍程度很低，但是又对结果有很严格的要求的场景下，或许是一个福音。

##### 1.5、延迟

延迟是相对于 watermarks 定义的。`Watermark(t)` 表示事件流的时间已经到达了 *t*; watermark 之后的时间戳 ≤ *t* 的任何事件都被称之为延迟事件。

##### 1.6、使用 Watermarks

使用基于带有事件时间戳的事件流，Flink 需要知道与每个事件相关的时间戳，而且流必须包含 watermark。

从事件中提取时间戳，并根据需要生成 watermarks。最简单的方法是使用 `WatermarkStrategy`：

```java
DataStream<Event> stream = ...

WatermarkStrategy<Event> strategy = WatermarkStrategy
        .<Event>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withTimestampAssigner((event, timestamp) -> event.timestamp);

DataStream<Event> withTimestampsAndWatermarks =
    stream.assignTimestampsAndWatermarks(strategy);
```

#### 2、窗口（Windows）

##### 2.1、概要

操作无界数据流时，经常需要应对以下问题，把无界数据流分解成有界数据流聚合分析:

- 每分钟的浏览量
- 每位用户每周的会话数
- 每个传感器每分钟的最高温度

用 Flink 计算窗口分析取决于两个主要的抽象操作：*Window Assigners*，将事件分配给窗口（根据需要创建新的窗口对象），以及 *Window Functions*，处理窗口内的数据。

Flink 的窗口 API 还具有 *Triggers* 和 *Evictors* 的概念，*Triggers* 确定何时调用窗口函数，而 *Evictors* 则可以删除在窗口中收集的元素。

举一个简单的例子，一般这样使用键控事件流（基于 key 分组的输入事件流）：

```ascii
stream.
    .keyBy(<key selector>)
    .window(<window assigner>)
    .reduce|aggregate|process(<window function>)
```

不是必须使用键控事件流（keyed stream），但是，**如果不使用键控事件流，程序将不能 *并行* 处理**。

```
stream.
    .windowAll(<window assigner>)
    .reduce|aggregate|process(<window function>)
```

##### 2.2、窗口分配器

Flink 的一些内置窗口分配器，如下：

![Window assigners](/assets/window-assigners.svg)

应用示例：

- 滚动时间窗口
  - *每分钟页面浏览量*
  - `TumblingEventTimeWindows.of(Time.minutes(1))`
- 滑动时间窗口
  - *每10秒钟计算前1分钟的页面浏览量*
  - `SlidingEventTimeWindows.of(Time.minutes(1), Time.seconds(10))`
- 会话窗口
  - *每个会话的网页浏览量，其中会话之间的间隔至少为30分钟*
  - `EventTimeSessionWindows.withGap(Time.minutes(30))`

此外，可以使用的间隔时间包括： `Time.milliseconds(n)`, `Time.seconds(n)`, `Time.minutes(n)`, `Time.hours(n)`, 和 `Time.days(n)`。

基于时间的窗口分配器（包括会话时间）既可以处理 `事件时间`，也可以处理 `处理时间`。这两种基于时间的处理没有哪一个更好，必须折衷。使用 `处理时间`，必须接受以下限制：

- 无法正确处理历史数据,
- 无法正确处理超过最大无序边界的数据,
- 结果将是不确定的,

但是它有自己的优势，较低的延迟。

使用基于计数的窗口时，请记住，只有窗口内的事件数量到达窗口要求的数值时，这些窗口才会触发计算。尽管可以使用自定义触发器自己实现该行为，但无法应对超时和处理部分窗口。

可能在有些场景下，想使用全局窗口分配器将每个事件（相同的 key）都分配给某一个指定的全局窗口。 很多情况下，一个比较好的建议是使用 `ProcessFunction`，详见[process functions](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html#process-functions)。

##### 2.3、窗口应用函数

三种最基本的操作窗口内的事件的选项:

1. 像批量处理，`ProcessWindowFunction` 会缓存 `Iterable` 和窗口内容，供接下来全量计算；
2. 或者像流处理，每一次有事件被分配到窗口时，都会调用 `ReduceFunction` 或者 `AggregateFunction` 来增量计算；
3. 或者结合两者，通过 `ReduceFunction` 或者 `AggregateFunction` 预聚合的增量计算结果在触发窗口时， 提供给 `ProcessWindowFunction` 做全量计算。

示例，在每一个一分钟大小的事件时间窗口内, 生成一个包含 `(key,end-of-window-timestamp, max_value)` 的一组结果。分别用这三种选项来实现。

###### 2.3.1、ProcessWindowFunction 示例

```java
DataStream<SensorReading> input = ...

input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .process(new MyWastefulMax());

public static class MyWastefulMax extends ProcessWindowFunction<
        SensorReading,                  // 输入类型
        Tuple3<String, Long, Integer>,  // 输出类型
        String,                         // 键类型
        TimeWindow> {                   // 窗口类型

    @Override
    public void process(
            String key,
            Context context,
            Iterable<SensorReading> events,
            Collector<Tuple3<String, Long, Integer>> out) {

        int max = 0;
        for (SensorReading event : events) {
            max = Math.max(event.value, max);
        }
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }
}
```

这个实现中，有些值得关注的地方：

- Flink 会缓存所有分配给窗口的事件流，直到触发窗口为止。这个操作可能是相高开销的。
- Flink 会传递给 `ProcessWindowFunction` 一个 `Context` 对象，这个对象内包含了一些窗口信息。`Context` 接口 展示大致如下:

```java
public abstract class Context implements java.io.Serializable {
    public abstract W window();

    public abstract long currentProcessingTime();
    public abstract long currentWatermark();

    public abstract KeyedStateStore windowState();
    public abstract KeyedStateStore globalState();
}
```

`windowState` 和 `globalState` 可以用来存储当前的窗口的 key、窗口或者当前 key 的每一个窗口信息。这在一些场景下会很有用，比如，在处理当前窗口的时候，可能会用到上一个窗口的信息。

###### 2.3.2、增量聚合示例

```java
DataStream<SensorReading> input = ...

input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .reduce(new MyReducingMax(), new MyWindowFunction());

private static class MyReducingMax implements ReduceFunction<SensorReading> {
    public SensorReading reduce(SensorReading r1, SensorReading r2) {
        return r1.value() > r2.value() ? r1 : r2;
    }
}

private static class MyWindowFunction extends ProcessWindowFunction<
    SensorReading, Tuple3<String, Long, SensorReading>, String, TimeWindow> {

    @Override
    public void process(
            String key,
            Context context,
            Iterable<SensorReading> maxReading,
            Collector<Tuple3<String, Long, SensorReading>> out) {

        SensorReading max = maxReading.iterator().next();
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }
}
```

其中 `Iterable<SensorReading>` 将只包含一个读数 – `MyReducingMax` 计算出的预先汇总的最大值。

##### 2.4、晚到的事件

默认场景下，超过最大无序边界的事件会被删除，此外，Flink 还可以去控制这些事件。

可以使用一种称为[旁路输出](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html#side-outputs) 的机制来安排将要删除的事件收集到侧输出流中

```java
OutputTag<Event> lateTag = new OutputTag<Event>("late"){};

SingleOutputStreamOperator<Event> result = stream.
    .keyBy(...)
    .window(...)
    .sideOutputLateData(lateTag)
    .process(...);

DataStream<Event> lateStream = result.getSideOutput(lateTag);
```

还可以指定 *允许的延迟(allowed lateness)* 的间隔，在这个间隔时间内，延迟的事件将会继续分配给窗口（同时状态会被保留），默认状态下，每个延迟事件都会导致窗口函数被再次调用（有时也称之为 *late firing* ）。

默认情况下，允许的延迟为 0。即，watermark 之后的元素将被丢弃（或发送到侧输出流）。

举例说明:

```java
stream.
    .keyBy(...)
    .window(...)
    .allowedLateness(Time.seconds(10))
    .process(...);
```

当允许的延迟大于零时，只有那些超过最大无序边界以至于会被丢弃的事件才会被发送到侧输出流（如果已配置）。

##### 2.5、深入了解窗口操作

Flink 的窗口 API 某些方面有一些奇怪的行为

###### 2.5.1、滑动窗口是通过复制实现的

滑动窗口分配器可以创建许多窗口对象，并将每个事件复制到每个相关的窗口中。例如，如果每隔 15 分钟就有一个 24 小时的滑动窗口，则每个事件将被复制到 4 * 24 = 96 个窗口中。

###### 2.5.2、时间窗口会和时间对齐

如果使用的是一个小时的处理时间窗口并在 12:05 开始运行应用程序，并不意味着第一个窗口将在 1:05 关闭。第一个窗口将长 55 分钟，并在 1:00 关闭。

滑动窗口和滚动窗口分配器所采用的 offset 参数可用于改变**窗口的对齐方式**。详见 [滚动窗口](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html#tumbling-windows) 和 [滑动窗口](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html#sliding-windows) 。

###### 2.5.3、窗口后可以接窗口

比如：

```java
stream
    .keyBy(t -> t.key)
    .window(<window assigner>)
    .reduce(<reduce function>)
    .windowAll(<same window assigner>)
    .reduce(<same reduce function>)
```

这样做是可行的，但是，前提是使用的是 ReduceFunction 或 AggregateFunction。因为时间窗口产生的事件是根据窗口结束时的时间分配时间戳的。后面的窗口内的数据消费和前面的流产生的数据是一致的。

###### 2.5.4、空的时间窗口不会输出结果

事件会触发窗口的创建。换句话说，如果在特定的窗口内没有事件，就不会有窗口，就不会有输出结果。

###### 2.5.5、延迟的事件（Late Events）会导致延迟的合并（Late Merges）

会话窗口的实现是基于窗口的一个抽象能力，窗口可以 *聚合*。会话窗口中的每个数据在初始被消费时，都会被分配一个新的窗口，但是如果窗口之间的间隔足够小，多个窗口就会被聚合。延迟事件可以弥合两个先前分开的会话间隔，从而产生一个虽然有延迟但是更加准确地结果。

