### 流式分析

#### 1、Event Time 和 Watermarks

##### 1.1、概要

Flink 明确支持以下三种不同的时间概念：

- *事件时间（event time）*：事件产生的时间，记录的是设备生成（或存储）事件的时间
- *摄取时间（ingestion time）*：Flink 读取事件时的时间戳
- *处理时间（processing time）*：Flink pipeline 中某个特定算子（operator）处理事件的时间

对于可重现的结果，比如，计算某只股票过去某一天第一个小时的最高价格时，应该使用事件时间。这样，运算的结果不会被运算执行的时间决定。这种类型的实时应用有时会使用处理时间，但是此时实时应用程序的结果就是是由程序运行的时间所决定，而不是由事件发生时间决定的。基于处理时间运行分析会导致不一致性，会使重新计算历史数据或者测试新的实现变得困难。

##### 1.2、使用 Event Time

如果要使用事件时间，需要提供一个时间戳提取器（Timestamp Extractor）和水印生成器（Watermark Generator），Flink 将使用它们来跟踪事件时间的进度。

##### 1.3、水印（Watermarks）

通过一个简单的例子来看为什么需要水印，以及水印是如何工作的。

如下是混乱的带有时间戳的事件的流。显示的数字表达的是这些事件实际发生时间的时间戳。到达的第一个事件发生在时间 4，随后发生的事件发生在更早的时间 2，依此类推：

###### ··· 23 19 22 24 21 14 17 13 12 15 9 11 7 2 4 

假设要创建一个流排序器（stream sorter）：在数据流里的事件到达时就开始处理事件，并输出按照时间戳排序好的事件。

重新审视一下这些数据:

1. 排序器看到的第一个事件的时间戳是 4，但是不能立即将其作为已排序的流发出。因为并不能确定它是有序的，并且较早的事件有可能并未到达。因此，*需要一些缓冲，有必要延迟一些时间*。

2. 如果一直等待，那么永远不会有结果。

3. 需要一种策略：对于任何给定时间戳的事件，Flink 何时停止等待较早事件的到来。*watermarks 的作用就是定义何时停止等待较早的事件*。

   Flink 中事件时间的处理取决于 *水印生成器* ——将带有时间戳的特殊元素 *水印* 插入到流中。时间为 *t* 的水印假设时间 *t* 期间流（很可能）都已经完整地到达。

4. 还可以想象不同的决定生成水印的策略

   每个事件都会延迟一段时间后到达，然而这些延迟有所不同，有些事件可能比其他事件延迟得更多。一种简单的方法是假定这些延迟受某个最大延迟的限制。Flink 将此策略称为 *无序边界 (bounded-out-of-orderness)* 水印。很容易想象其它更复杂的水印生成方法，但是对大多数的应用来说，一个固定的延时就足够了。

##### 1.4、滞后性（Latency）VS 完整性（Completeness）

思考水印的另一种方式是——它让流式应用的开发者来控制滞后性和完整性之间取舍。与批处理不同，批处理中可以在产生任何结果之前完全了解输入，而使用流式传输，不能等待所有的事件都产生了，才输出排序好的数据。

可以把水印的边界时间配置的相对较短，从而冒着在输入了解不完整的情况下产生结果的风险——即可能会很快产生的、错误的结果。或者，以等待更长的时间，并利用对输入流的更全面的了解来产生结果。

当然也可以实施混合解决方案，先快速产生初步结果，然后在处理其他（最新）数据时向这些结果提供更新。对于有一些对延迟的容忍程度很低，但是又对结果有很严格的要求的场景下，这或许是一个福音。

##### 1.5、延迟（Lateness）

延迟是相对于 watermarks 定义的。`Watermark(t)` 表示事件流在时间 *t* 内已经完成，在这个水印之后的时间戳 ≤ *t* 的任何事件都是迟到的。

##### 1.6、使用水印

为了进行基于事件时间处理，Flink 需要知道与每个事件相关的时间，而且流必须包含水印。

通常通过实现一个类来从事件中提取时间戳，并根据需要生成水印。最简单的方法是使用 `WatermarkStrategy`：

```java
DataStream<Event> stream = ...

WatermarkStrategy<Event> strategy = WatermarkStrategy
        .<Event>forBoundedOutOfOrderness(Duration.ofSeconds(20))
        .withTimestampAssigner((event, timestamp) -> event.timestamp);

DataStream<Event> withTimestampsAndWatermarks =
    stream.assignTimestampsAndWatermarks(strategy);
```

#### 2、窗口（Windows）

Flink 具有非常有表现力的 window 语义。

本节介绍：

- 如何使用窗口对无边界流进行聚合
- Flink 支持哪些类型的窗口
- 怎样实现一个具有窗口聚合功能的 DataStream 程序

##### 2.1、概要

操作无界数据流时，经常需要对无界数据流的有界子集进行聚合分析，比如：

- 每分钟的浏览量
- 每位用户每周的会话数
- 每个传感器每分钟的最高温度

用 Flink 进行窗口分析依赖于两个主要的抽象（two principal abstractions）：*Window Assigners* ——将事件分配到窗口中（根据需要创建新的窗口对象），以及 *Window Functions* ——应用于分配到窗口内的事件上。

Flink 的开窗 API （windowing API）还具有 *Triggers* 和 *Evictors* 的概念，*Triggers* 确定何时调用窗口函数，而 *Evictors* 则可以删除在窗口中收集的元素。

基础形式，应用开窗（windowing）于一个键控流（keyed stream）：

```ascii
stream.
    .keyBy(<key selector>)
    .window(<window assigner>)
    .reduce|aggregate|process(<window function>)
```

还可以对非键控流（non-keyed streams）使用开窗，但是，**如果不使用键控事件流，处理将不能 *并行* 进行**。

```
stream.
    .windowAll(<window assigner>)
    .reduce|aggregate|process(<window function>)
```

##### 2.2、窗口分配器（Window Assigners）

Flink 的一些内置窗口分配器类型，如下：

![Window assigners](/assets/window-assigners.svg)

一些窗口的应用示例：

- **滚动时间窗口**
  - *每分钟页面浏览量*
  - `TumblingEventTimeWindows.of(Time.minutes(1))`
- **滑动时间窗口**
  - *每 10 秒钟计算每 1 分钟的页面浏览量*
  - `SlidingEventTimeWindows.of(Time.minutes(1), Time.seconds(10))`
- **会话窗口**
  - *每个会话的网页浏览量，其中会话通过会话之间至少为30分钟的间隔来定义*
  - `EventTimeSessionWindows.withGap(Time.minutes(30))`

此外，可以使用的间隔时间包括： `Time.milliseconds(n)`, `Time.seconds(n)`, `Time.minutes(n)`, `Time.hours(n)`, 和 `Time.days(n)`。

基于时间的窗口分配器（包括会话时间）包括处理 `事件时间` 和处理 `处理时间` 两种类型。这两种类型的时间窗口之间存在重大权衡。使用 `处理时间` 开窗，必须接受以下限制：

- 无法正确处理历史数据,
- 无法正确处理超过无序的（out-of-order）数据,
- 结果将是不确定的,

但是它有自己的优势，较低的延迟。

使用基于计数的（count-based）窗口时，请记住，只有窗口内的事件数量到达窗口要求的数值时，这些窗口才会触发计算。这种类型的窗口不具有超时和处理部分窗口的选项，尽管可以使用自定义触发器自己实现这些行为。

全局窗口分配器（global window assigner）将具有相同键的每个事件分配给相同的全局窗口。只有在使用自定的触发器进行自定义开窗的时候这个才有用。在类似的很多情况下，一个比较好的建议是转向使用 `ProcessFunction`，详见[process functions](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html#process-functions)。

##### 2.3、窗口函数（Window Functions）

三个基本的操作窗口内事件的选项:

1. 作为批次进行（as a batch）处理——使用`ProcessWindowFunction`， 会将一个包含窗口内容的 `Iterable` 传递给该函数进行处理；
2. 增量地（incrementally）处理——用 `ReduceFunction` 或者 `AggregateFunction` ，每当有事件被分配到窗口时调用函数进行处理；
3. 或者结合两者——当窗口触发时，`ReduceFunction` 或者 `AggregateFunction` 的预聚合（pre-aggregated）结果会应用到 `ProcessWindowFunction`。

如下为方式 1 和方式 3 的示例。在每个传感器一分钟的事件时间窗口内查找峰值（peak value）, 生成一个包含元组 `(key,end-of-window-timestamp, max_value)` 的流。

###### 2.3.1、ProcessWindowFunction 示例

```java
DataStream<SensorReading> input = ...

input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .process(new MyWastefulMax());

public static class MyWastefulMax extends ProcessWindowFunction<
        SensorReading,                  // 输入类型
        Tuple3<String, Long, Integer>,  // 输出类型
        String,                         // 键类型
        TimeWindow> {                   // 窗口类型

    @Override
    public void process(
            String key,
            Context context,
            Iterable<SensorReading> events,
            Collector<Tuple3<String, Long, Integer>> out) {

        int max = 0;
        for (SensorReading event : events) {
            max = Math.max(event.value, max);
        }
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }
}
```

需要注意的是：

- 分配到窗口的所有的时间都会被缓存到键控的 Flink 状态（keyed Flink state），一直到窗口被触发。这是潜在的高开销。
- `ProcessWindowFunction`  会被传递一个 `Context` 对象，这个对象内包含了窗口的信息。`Context` 接口如下：

```java
public abstract class Context implements java.io.Serializable {
    public abstract W window();

    public abstract long currentProcessingTime();
    public abstract long currentWatermark();

    public abstract KeyedStateStore windowState();
    public abstract KeyedStateStore globalState();
}
```

`windowState` 和 `globalState` 是可以用来存储按 key 信息、按窗口信息、或者某个 key 的所有窗口的全局的按 key 信息的地方。这在一些场景下会很有用，比如，在处理随后的（subsequent）窗口的时候，可能会想用到当前窗口的一些东西。

###### 2.3.2、增量聚合示例（Incremental Aggregation Example）

```java
DataStream<SensorReading> input = ...

input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .reduce(new MyReducingMax(), new MyWindowFunction());

private static class MyReducingMax implements ReduceFunction<SensorReading> {
    public SensorReading reduce(SensorReading r1, SensorReading r2) {
        return r1.value() > r2.value() ? r1 : r2;
    }
}

private static class MyWindowFunction extends ProcessWindowFunction<
    SensorReading, Tuple3<String, Long, SensorReading>, String, TimeWindow> {

    @Override
    public void process(
            String key,
            Context context,
            Iterable<SensorReading> maxReading,
            Collector<Tuple3<String, Long, SensorReading>> out) {

        SensorReading max = maxReading.iterator().next();
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }
}
```

其中 `Iterable<SensorReading>` 将只包含一个读数 – `MyReducingMax` 计算出的预先聚合的（pre-aggreagated）最大值。

##### 2.4、晚到的事件（Late Events）

使用事件时间窗口时，默认场景下，迟到的事件会被删除。window API 还可以去采用其他方式处理迟到事件。

可以使用一种称为 [旁路输出](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/learn-flink/event_driven.html#side-outputs)（Side Output） 的机制，把将要被删除的事件收集到备用（alternate）输出流中：

```java
OutputTag<Event> lateTag = new OutputTag<Event>("late"){};

SingleOutputStreamOperator<Event> result = stream.
    .keyBy(...)
    .window(...)
    .sideOutputLateData(lateTag)
    .process(...);

DataStream<Event> lateStream = result.getSideOutput(lateTag);
```

还可以指定*允许的延迟（allowed lateness）* 间隔，延迟的事件将会继续分配给合适的窗口（它们的状态会被保留）。默认状态下，每个延迟事件都会导致窗口函数被再次调用（有时也称之为迟到触发 *late firing* ）。

默认情况下，允许的延迟为 0。即，watermark 之后的元素将被丢弃（或发送到侧输出流）。

举例说明:

```java
stream.
    .keyBy(...)
    .window(...)
    .allowedLateness(Time.seconds(10))
    .process(...);
```

当允许的延迟大于零时，只有那些超过允许延迟的事件以至于会被丢弃的事件才会被发送到旁路输出流（如果配置了旁路输出）。

##### 2.5、吃惊的地方（Surprises）

Flink 的窗口 API 在某些方面可能有一些与预想不同的奇怪行为

###### 2.5.1、滑动窗口是通过复制实现的

滑动窗口分配器可以创建许多窗口对象，并将每个事件复制到每个相关的窗口中。例如，如果每隔 15 分钟就有一个 24 小时的滑动窗口，则每个事件将被复制到 4 * 24 = 96 个窗口中。

###### 2.5.2、时间窗口会和时间对齐（Time Windows are Aligned to the Epoch）

如果使用的是一个小时的处理时间窗口并在 12:05 开始运行应用程序，并不意味着第一个窗口将在 1:05 关闭。第一个窗口将长 55 分钟，并在 1:00 关闭。

但是，滑动窗口和滚动窗口分配器使用一个可选的 offset 参数可用于改变**窗口的对齐方式**。详见 [滚动窗口](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html#tumbling-windows) 和 [滑动窗口](https://ci.apache.org/projects/flink/flink-docs-release-1.12/zh/dev/stream/operators/windows.html#sliding-windows) 。

###### 2.5.3、窗口后可以接窗口（Windows Can Follow Windows）

比如：

```java
stream
    .keyBy(t -> t.key)
    .window(<window assigner>)
    .reduce(<reduce function>)
    .windowAll(<same window assigner>)
    .reduce(<same reduce function>)
```

获取这样编码的期望是，让 Flink 先进行并行的预聚合，但是不行！！！

这样编码是能够运行的，是因为时间窗口产生的事件是根据窗口结束时的时间分配时间戳的。所以，比如，一个小时时长的窗口产生的所有的事件都会有标记为一个小时的结束的时间戳，后续的窗口消费这些事件应该喝前面的窗口具有相同时长或者倍数时长。

###### 2.5.4、空的时间窗口不会输出结果（No Results for Empty TimeWindows）

当事件被分配给窗口时，窗口才会被创建。如果在特定的窗口内没有事件，就不会有窗口，就不会有输出结果。

###### 2.5.5、延迟的事件（Late Events）会导致延迟的合并（Late Merges）

会话窗口是基于窗口的一个抽象能力——窗口可以 *合并（merge）*。每个元素最初被分配给一个新的窗口，当窗口之间的间隔（gap）足够小，多个窗口就会被合并。这样，迟到事件可以弥合两个先前分开的会话之间的间隔，从而产生一个延迟的合并。

